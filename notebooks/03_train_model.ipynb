{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a1ce84b",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "This notebook is responsible for training the image classification model.\n",
    "It will load the processed data, define the model architecture, set up the training loop, and save the trained model and relevant artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182d4491",
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root '/workspaces/photo_tag_pipeline' is already in sys.path.\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "from IPython.display import Image\n",
    "\n",
    "# Add the project root to the Python path\n",
    "# This allows importing modules from the 'src' directory\n",
    "current_path = Path(os.getcwd()).resolve()\n",
    "project_root = None\n",
    "# Iterate up from current_path to its parents\n",
    "for parent_dir in [current_path] + list(current_path.parents):\n",
    "    if (\n",
    "        (parent_dir / \".git\").is_dir()\n",
    "        or (parent_dir / \"pyproject.toml\").is_file()\n",
    "        or (parent_dir / \"src\").is_dir()\n",
    "    ):\n",
    "        project_root = parent_dir\n",
    "        break\n",
    "\n",
    "if project_root is None:\n",
    "    # Fallback for structures where notebook is in 'notebooks' dir directly under project root\n",
    "    if current_path.name == \"notebooks\" and (current_path.parent / \"src\").is_dir():\n",
    "        project_root = current_path.parent\n",
    "    else:\n",
    "        # Default to current_path if specific markers or 'notebooks' structure isn't found\n",
    "        project_root = current_path\n",
    "        print(\n",
    "            f\"Warning: Could not reliably find project root. Using CWD: {project_root}. Ensure 'src' is in python path.\"\n",
    "        )\n",
    "\n",
    "if project_root:\n",
    "    project_root_str = str(project_root)\n",
    "    if project_root_str not in sys.path:\n",
    "        sys.path.insert(0, project_root_str)\n",
    "        print(f\"Project root '{project_root_str}' added to sys.path.\")\n",
    "    else:\n",
    "        print(f\"Project root '{project_root_str}' is already in sys.path.\")\n",
    "else:\n",
    "    print(\"Error: Project root could not be determined. Imports from 'src' may fail.\")\n",
    "\n",
    "# Reload modules to ensure the latest changes are picked up\n",
    "# Useful if you're actively developing the src modules\n",
    "import src.config\n",
    "import src.data.loader\n",
    "import src.models.PhotoTagNet_model\n",
    "import src.models.basic_model\n",
    "import src.utils.seed\n",
    "import src.utils.plot\n",
    "\n",
    "importlib.reload(src.config)\n",
    "importlib.reload(src.data.loader)\n",
    "importlib.reload(src.models.PhotoTagNet_model)\n",
    "importlib.reload(src.models.basic_model)\n",
    "importlib.reload(src.utils.seed)\n",
    "importlib.reload(src.utils.plot)\n",
    "from sympy import Basic\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm.auto import tqdm  # For progress bars\n",
    "\n",
    "from src.models.PhotoTagNet_model import PhotoTagNet\n",
    "\n",
    "# Imports from our src directory\n",
    "from src.config import (\n",
    "    ModelConfig,\n",
    "    OptimConfig,\n",
    "    TrainConfig,\n",
    "    CHECKPOINT_DIR,\n",
    "    RESULTS_DIR,\n",
    ")\n",
    "from src.config import DEFAULT_CLASSES\n",
    "from src.data.loader import load_data\n",
    "from src.models.basic_model import BasicMLC\n",
    "from src.utils.seed import set_seed\n",
    "from src.utils.plot import save_loss_plot\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df36be0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainConfig: TrainConfig(epochs=30, seed=42, precision_at_k=5, early_stop_patience=7)\n",
      "ModelConfig: ModelConfig(backbone='resnet50', pretrained=True, freeze_backbone=False, dropout_rate=0.3)\n",
      "OptimConfig: OptimConfig(optim='adamw', lr=0.0003, weight_decay=0.0001, betas=(0.9, 0.999), momentum=0.9, scheduler='step', step_size=5, gamma=0.5, patience=5)\n",
      "Seed set to 42\n",
      "Loading data...\n",
      "Data loaded. Train batches: 39, Val batches: 6\n",
      "Building model...\n",
      "Model, criterion, and optimizer created.\n",
      "Starting training for 30 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 [Training]: 100%|██████████| 39/39 [00:16<00:00,  2.40batch/s, loss=0.313]\n",
      "Epoch 1/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  5.14batch/s, loss=0.14] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 - Train Loss: 0.3938, Val Loss: 0.2401\n",
      "New best model saved to /workspaces/photo_tag_pipeline/checkpoints/best_model_notebook.pth (Val Loss: 0.2401)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 [Training]: 100%|██████████| 39/39 [00:17<00:00,  2.20batch/s, loss=0.236]\n",
      "Epoch 2/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  5.03batch/s, loss=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 - Train Loss: 0.2235, Val Loss: 0.3014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 [Training]: 100%|██████████| 39/39 [00:20<00:00,  1.87batch/s, loss=0.236]\n",
      "Epoch 3/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  3.62batch/s, loss=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 - Train Loss: 0.1886, Val Loss: 0.2768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 [Training]: 100%|██████████| 39/39 [00:21<00:00,  1.77batch/s, loss=0.143]\n",
      "Epoch 4/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  4.49batch/s, loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 - Train Loss: 0.1491, Val Loss: 0.2898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Training]: 100%|██████████| 39/39 [00:20<00:00,  1.95batch/s, loss=0.1]   \n",
      "Epoch 5/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  4.76batch/s, loss=0.242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Train Loss: 0.1144, Val Loss: 0.3312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Training]: 100%|██████████| 39/39 [00:18<00:00,  2.07batch/s, loss=0.164] \n",
      "Epoch 6/30 [Validation]: 100%|██████████| 6/6 [00:03<00:00,  1.92batch/s, loss=0.184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 - Train Loss: 0.0960, Val Loss: 0.3487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Training]: 100%|██████████| 39/39 [00:18<00:00,  2.09batch/s, loss=0.0772]\n",
      "Epoch 7/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  3.74batch/s, loss=0.0607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Train Loss: 0.0851, Val Loss: 0.3878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Training]: 100%|██████████| 39/39 [00:18<00:00,  2.15batch/s, loss=0.0532]\n",
      "Epoch 8/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  4.85batch/s, loss=0.372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - Train Loss: 0.0801, Val Loss: 0.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Training]: 100%|██████████| 39/39 [00:18<00:00,  2.05batch/s, loss=0.0776]\n",
      "Epoch 9/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  4.87batch/s, loss=0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - Train Loss: 0.0618, Val Loss: 0.3374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Training]: 100%|██████████| 39/39 [00:20<00:00,  1.90batch/s, loss=0.0416]\n",
      "Epoch 10/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  4.60batch/s, loss=0.111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Train Loss: 0.0507, Val Loss: 0.3503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Training]: 100%|██████████| 39/39 [00:18<00:00,  2.09batch/s, loss=0.0503]\n",
      "Epoch 11/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  4.80batch/s, loss=0.223]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 - Train Loss: 0.0508, Val Loss: 0.3773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Training]: 100%|██████████| 39/39 [00:33<00:00,  1.15batch/s, loss=0.0479]\n",
      "Epoch 12/30 [Validation]: 100%|██████████| 6/6 [00:02<00:00,  2.86batch/s, loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Train Loss: 0.0484, Val Loss: 0.3797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Training]: 100%|██████████| 39/39 [00:23<00:00,  1.65batch/s, loss=0.022] \n",
      "Epoch 13/30 [Validation]: 100%|██████████| 6/6 [00:01<00:00,  3.97batch/s, loss=0.222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 - Train Loss: 0.0420, Val Loss: 0.3704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 [Training]:  67%|██████▋   | 26/39 [00:18<00:09,  1.38batch/s, loss=0.0367] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     47\u001b[39m outputs = model(imgs)\n\u001b[32m     48\u001b[39m loss = criterion(outputs, labels)\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m optimizer.step()\n\u001b[32m     52\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Ensure results and plots directories exist for storing outputs\n",
    "PLOTS_DIR = RESULTS_DIR / \"plots\"\n",
    "RESULTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "PLOTS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# ---- Configurations ----\n",
    "mcfg = ModelConfig()\n",
    "ocfg = OptimConfig()\n",
    "tcfg = TrainConfig()\n",
    "\n",
    "print(f\"TrainConfig: {tcfg}\")\n",
    "print(f\"ModelConfig: {mcfg}\")\n",
    "print(f\"OptimConfig: {ocfg}\")\n",
    "\n",
    "# ---- Set Seed ----\n",
    "set_seed(tcfg.seed)\n",
    "print(f\"Seed set to {tcfg.seed}\")\n",
    "\n",
    "# ---- Data Loaders ----\n",
    "print(\"Loading data...\")\n",
    "train_dataset, val_dataset, train_loader, val_loader = load_data()\n",
    "print(\n",
    "    f\"Data loaded. Train batches: {len(train_loader)}, Val batches: {len(val_loader)}\"\n",
    ")\n",
    "\n",
    "\n",
    "# ---- Model, Loss, Optimizer ----\n",
    "print(\"Building model...\")\n",
    "model = BasicMLC(len(DEFAULT_CLASSES)).to(DEVICE)\n",
    "# model = PhotoTagNet(ModelConfig(), num_classes=len(DEFAULT_CLASSES)).to(DEVICE)\n",
    "criterion = (\n",
    "    nn.BCEWithLogitsLoss()\n",
    ")  # Binary Cross-Entropy for multi-label with sigmoid output\n",
    "optimizer = optim.AdamW(model.parameters(), lr=ocfg.lr, weight_decay=ocfg.weight_decay)\n",
    "print(\"Model, criterion, and optimizer created.\")\n",
    "\n",
    "\n",
    "# ---- Training Loop ----\n",
    "best_val_loss = float(\"inf\")\n",
    "train_losses, val_losses = [], []\n",
    "\n",
    "print(f\"Starting training for {tcfg.epochs} epochs...\")\n",
    "for epoch in range(tcfg.epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch+1}/{tcfg.epochs} [Training]\", unit=\"batch\"\n",
    "    )\n",
    "    for imgs, labels in progress_bar:\n",
    "        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # ---- Validation ----\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        progress_bar_val = tqdm(\n",
    "            val_loader, desc=f\"Epoch {epoch+1}/{tcfg.epochs} [Validation]\", unit=\"batch\"\n",
    "        )\n",
    "        for imgs, labels in progress_bar_val:\n",
    "            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_running_loss += loss.item()\n",
    "            progress_bar_val.set_postfix(loss=loss.item())\n",
    "\n",
    "    val_loss = val_running_loss / len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{tcfg.epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ---- Checkpoint ----\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_path = CHECKPOINT_DIR / \"best_model_notebook.pth\"\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(\n",
    "            f\"New best model saved to {best_model_path} (Val Loss: {best_val_loss:.4f})\"\n",
    "        )\n",
    "\n",
    "# ---- Save Final Model ----\n",
    "final_model_path = CHECKPOINT_DIR / \"final_model_notebook.pth\"\n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "print(f\"Final model saved to {final_model_path}\")\n",
    "\n",
    "# ---- Plot and Save Loss Curve ----\n",
    "# Ensure results directory exists (though config should handle it)\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "loss_plot_path = save_loss_plot(\n",
    "    train_losses, val_losses, str(\"loss_curve_notebook.png\")\n",
    ")\n",
    "print(f\"Loss curve saved to {loss_plot_path}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# Display the plot in the notebook\n",
    "display(Image(filename=str(loss_plot_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047feb24",
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Check if mlflow is installed and start the UI if available\n",
    "try:\n",
    "    mlflow_port = 5000\n",
    "    mlflow_ui_proc = subprocess.Popen(\n",
    "        [\"mlflow\", \"ui\", \"--port\", str(mlflow_port), \"--host\", \"0.0.0.0\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "    )\n",
    "    print(f\"MLflow UI started on port {mlflow_port}.\")\n",
    "    # Open in host browser if $BROWSER is available\n",
    "    if \"BROWSER\" in os.environ:\n",
    "        os.system(f\"$BROWSER http://localhost:{mlflow_port}\")\n",
    "    else:\n",
    "        print(f\"Open http://localhost:{mlflow_port} in your browser.\")\n",
    "except ImportError:\n",
    "    print(\"mlflow is not installed. Please install it with `pip install mlflow`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b133aa",
   "metadata": {},
   "source": [
    "After training, the model will be saved to the `checkpoints/` directory (e.g., `best_model_notebook.pth`, `final_model_notebook.pth`), and the loss curve plot will be saved in the `results/` directory (e.g., `loss_curve_notebook.png`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6024e8dc",
   "metadata": {
    "tags": [
     "remove"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import HTML\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Get current notebook name\n",
    "try:\n",
    "    # Try to get the notebook name using IPython's special variable\n",
    "    notebook_path = (\n",
    "        get_ipython().kernel.shell.user_ns[\"__vsc_ipynb_file__\"]\n",
    "        if \"__vsc_ipynb_file__\" in get_ipython().kernel.shell.user_ns\n",
    "        else None\n",
    "    )\n",
    "    if not notebook_path:\n",
    "        notebook_path = get_ipython().kernel.shell.user_ns.get(\n",
    "            \"__notebook_source__\", \"\"\n",
    "        )\n",
    "    notebook_name = os.path.basename(notebook_path) if notebook_path else \"\"\n",
    "except:\n",
    "    notebook_name = \"\"\n",
    "\n",
    "# Check if the notebook name was successfully determined\n",
    "if notebook_name == \"\":\n",
    "    # Fallback method if automatic detection fails\n",
    "    notebook_name = input(\"Enter notebook filename (with .ipynb extension): \")\n",
    "\n",
    "# Use nbconvert to export the notebook without input cells tagged with \"remove\"\n",
    "# Ensure the assets directory exists\n",
    "assets_dir = \"../assets\"\n",
    "os.makedirs(assets_dir, exist_ok=True)\n",
    "output_html = os.path.join(\n",
    "    assets_dir, os.path.splitext(os.path.basename(notebook_name))[0] + \"_export.html\"\n",
    ")\n",
    "!jupyter nbconvert --to html --TagRemovePreprocessor.remove_cell_tags='{\"remove\"}' \"{notebook_name}\" --output \"{output_html}\"\n",
    "\n",
    "# Display a success message\n",
    "display(\n",
    "    HTML(\n",
    "        f\"<div style=padding:10px;'>\"\n",
    "        f\"<h3>Export complete!</h3>\"\n",
    "        f\"<p>Notebook <b>{notebook_name}</b> has been exported to HTML.</p>\"\n",
    "        f\"</div>\"\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
